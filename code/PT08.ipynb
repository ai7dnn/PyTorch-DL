{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soobook/PyTorch-DL/blob/main/code/PT08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8회차: CNN을 활용한 컬러 이미지 분류 (2) – 데이터 처리 및 모델 구현\n"
      ],
      "metadata": {
        "id": "-WQglOpLugjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 로드\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "A52iqSfO_o11"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터 전처리(이미지 변환, 데이터 증강)\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),    # 수평(좌우로)으로 반전, 데이터 증강\n",
        "    transforms.RandomCrop(32, padding=4), # 무작위잘라내기, 데이터 증강\n",
        "    transforms.ToTensor(),                # 0 ~ 1로 변환, 데이터 스케일 조정\n",
        "    # 데이터 정규화\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), # 각 채널(R, G, B)의 평균\n",
        "                         (0.2023, 0.1994, 0.2010)) # 각 채널(R, G, B)의 표준편차\n",
        "\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                         (0.2023, 0.1994, 0.2010))\n",
        "])"
      ],
      "metadata": {
        "id": "K7T20hiRmWlo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리와 로드\n",
        "# 데이터 증강 방법을 인자 transform에 설정\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "# Dataset이 이미지를 꺼내는 시점에서 위에서 설정된 transform_train이 적용됨\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "vsux7Ev6CTuR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = trainset.classes\n",
        "print(classes)\n",
        "len(trainset), len(testset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XrKMJjjKtJY",
        "outputId": "2ea5ac2f-3f3d-4472-a23f-80e9e242d589"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. CNN 모델 정의\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            # 채널 수, 출력 필터인 feature map 수, 커널(필터)의 크기, 패딩 픽셀 수\n",
        "            # 내부적으로 (채널 수 × feature map 수) 만큼의 커널(필터)를 생성\n",
        "            # nn.Conv2d(3, 32, 3, padding=1),\n",
        "            # 32×32 → 32×32로 동일\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            # 컨볼루션 패라미터 수\n",
        "            # =   (필터_가로길이 × 필터_세로길이 × 입력채널수(in_channels) + 1(bias)) × 출력채널수(out_channels)\n",
        "            # =   (3 × 3 × 3 + 1) × 32\n",
        "            # =   896\n",
        "\n",
        "            # 학습 중에 배치 별로 각 채널(feature map)의 평균과 분산으로 정규화\n",
        "            # 각 미니배치마다 채널 32개의 출력 분포를 평균 0, 분산 1로 정규화하고,\n",
        "            # 학습 가능한 스케일·시프트 파라미터를 적용하는 계층 기법\n",
        "            # 학습 안정화, 수렴 속도 증가, 과적합 방지 효과\n",
        "            nn.BatchNorm2d(32),\n",
        "\n",
        "            # 비선형 활성화 함수 (Rectified Linear Unit)\n",
        "            # 음수는 0, 양수는 그대로 통과\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # 피처 맵(feature map)의 공간 크기를 줄이기 위해 사용\n",
        "            # 불필요한 정보(작은 값) 버리고, 가장 두드러진 특징만 남김\n",
        "            # 2×2 크기의 창(window)을 사용해, 그 안에서 최댓값만 추출\n",
        "            # 32×32 → 16×16로 줄어듦\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        # 특징(feature)의 추상화 수준이 더 깊어지고, 크기는 또 절반으로 줄어듦\n",
        "        self.layer2 = nn.Sequential(\n",
        "            # 32 채널 입력을 받아 64 채널로 확장, 결과 크기는 그대로 16×16\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            # 출력 크기가 16×16 → 8×8로 줄어듦\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            # 64 채널 입력을 받아 128 채널로 확장, 결과 크기는 그대로 8×8\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            # 출력 크기가 8×8 → 4×4로 줄어듦\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        # 4×4 피처 맵이 128개이므로 입력이  128 × 4 × 4 = 2048\n",
        "        # CIFAR-10 데이터, 출력 차원 10: 분류하고자 하는 클래스 수를 의미\n",
        "        # 2048차원 → 10차원으로 변환하는 선형 연산을 수행\n",
        "        self.fc = nn.Linear(128 * 4 * 4, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        # 평탄화하여 2차원으로 변환\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "_-Odg778Kh1j"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 합성공 이해\n",
        "- nn.Conv2d(in_channels=3, out_channels=2, kernel_size=3, padding=1, stride=2)\n",
        "- [스탠포드대학강좌](https://cs231n.github.io/convolutional-networks)\n"
      ],
      "metadata": {
        "id": "FVaLxhs3pLUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 모델 준비 및 구조 출력\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = SimpleCNN().to(device)\n",
        "# 인자 net: 정의한 신경망 모델 객체, 여기서는 합성곱(CNN) 신경망\n",
        "# 인자 (3, 32, 32): 입력 데이터의 크기\n",
        "# (채널=3, 높이=32, 너비=32) → CIFAR-10 이미지 크기\n",
        "summary(net, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrmJcBkHVVXv",
        "outputId": "cfca38b3-d803-4225-d6db-85c4f49e6412"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             896\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "              ReLU-3           [-1, 32, 32, 32]               0\n",
            "         MaxPool2d-4           [-1, 32, 16, 16]               0\n",
            "            Conv2d-5           [-1, 64, 16, 16]          18,496\n",
            "       BatchNorm2d-6           [-1, 64, 16, 16]             128\n",
            "              ReLU-7           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-8             [-1, 64, 8, 8]               0\n",
            "            Conv2d-9            [-1, 128, 8, 8]          73,856\n",
            "      BatchNorm2d-10            [-1, 128, 8, 8]             256\n",
            "             ReLU-11            [-1, 128, 8, 8]               0\n",
            "        MaxPool2d-12            [-1, 128, 4, 4]               0\n",
            "           Linear-13                   [-1, 10]          20,490\n",
            "================================================================\n",
            "Total params: 114,186\n",
            "Trainable params: 114,186\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.42\n",
            "Params size (MB): 0.44\n",
            "Estimated Total Size (MB): 1.87\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 파라미터 수 계산\n",
        "- Conv2d [-1, 64, 16, 16]: 필터크기=3×3, 18,496\n",
        "- (3×3×32 + 1) × 64 = 18,496"
      ],
      "metadata": {
        "id": "g5xrYd2h2y8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 종료"
      ],
      "metadata": {
        "id": "tAY8wuohzVqQ"
      }
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soobook/PyTorch-DL/blob/main/code/PT02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2회차: PyTorch 설치 및 기초 코딩"
      ],
      "metadata": {
        "id": "SazHYg839Ty7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CUDA(Compute Unified Device Architecture)\n",
        "- NVIDIA에서 만든 병렬 연산용 프로그래밍 프레임워크\n",
        "- GPU를 범용 컴퓨팅(GPGPU: General Purpose GPU) 작업에 활용"
      ],
      "metadata": {
        "id": "dYwn4WGEyY8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(f'파이토치 버전: {torch.__version__}')\n",
        "print(\"GPU\" if torch.cuda.is_available() else \"CPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qRQVy0rWF1D",
        "outputId": "2c4c771f-e504-411f-945c-7d2eee3951b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파이토치 버전: 2.8.0+cu126\n",
            "GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch 및 라이브러리 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "vyCAIVG4SZFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "N8nEcyfkVw_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리 및 로딩\n",
        "transform = transforms.ToTensor()\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGJXredwV1Hf",
        "outputId": "129d7170-099c-45fe-ec97-56e4d05989b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 507kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.71MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.72MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "O-H1zcJ7_Mu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_loader 정보 출력\n",
        "print(\"=== Train Loader Info ===\")\n",
        "print(f\"총 배치 수 (len): {len(train_loader)}\")    # 전체 배치 개수\n",
        "print(f\"총 샘플 수: {len(train_loader.dataset)}\")  # 전체 데이터 수\n",
        "print(f\"총 배치 수 (직접계산): {len(train_loader.dataset)//batch_size + 1}\")\n",
        "\n",
        "# 첫 번째 배치 샘플 shape 확인\n",
        "for images, labels in train_loader:\n",
        "    print(f\"이미지 shape: {images.shape}\")         # 예: [batch_size, 1, 28, 28]\n",
        "    print(f\"레이블 shape: {labels.shape}\")         # 예: [batch_size]\n",
        "    print(f\"데이터 타입: {images.dtype}, 라벨 dtype: {labels.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU5xTuWgXlId",
        "outputId": "c6b089ec-76d0-4c98-b94e-da3d3e81efe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train Loader Info ===\n",
            "총 배치 수 (len): 938\n",
            "총 샘플 수: 60000\n",
            "총 배치 수 (직접계산): 938\n",
            "이미지 shape: torch.Size([64, 1, 28, 28])\n",
            "레이블 shape: torch.Size([64])\n",
            "데이터 타입: torch.float32, 라벨 dtype: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_loader 정보 출력\n",
        "print(\"\\n=== Test Loader Info ===\")\n",
        "print(f\"총 배치 수 (len): {len(test_loader)}\")\n",
        "print(f\"총 샘플 수: {len(test_loader.dataset)}\")\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    print(f\"이미지 shape: {images.shape}\")\n",
        "    print(f\"레이블 shape: {labels.shape}\")\n",
        "    print(f\"데이터 타입: {images.dtype}, 라벨 dtype: {labels.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtAGk2LzYKkM",
        "outputId": "5840d147-e0a8-4137-c00a-aea99eb5b9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Test Loader Info ===\n",
            "총 배치 수 (len): 157\n",
            "총 샘플 수: 10000\n",
            "이미지 shape: torch.Size([64, 1, 28, 28])\n",
            "레이블 shape: torch.Size([64])\n",
            "데이터 타입: torch.float32, 라벨 dtype: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch의 기본 신경망 모듈 nn.Module을 상속받아 DNN 클래스 정의\n",
        "class DNN(nn.Module):\n",
        "\n",
        "    # 클래스 초기화 메서드: 모델의 레이어들을 정의\n",
        "    def __init__(self):\n",
        "        # 부모 클래스(nn.Module)의 생성자를 호출해 초기화\n",
        "        super(DNN, self).__init__()\n",
        "        # 입력 데이터를 1차원으로 평탄화(28x28 → 784차원)\n",
        "        self.flatten = nn.Flatten()\n",
        "        # 여러 층을 순차적으로 쌓은 신경망 정의\n",
        "        self.model = nn.Sequential(\n",
        "            # 입력층(784) → 은닉층(128)\n",
        "            nn.Linear(28*28, 128),\n",
        "            # 활성화 함수 ReLU 적용\n",
        "            nn.ReLU(),\n",
        "            # 은닉층(128) → 은닉층(64)\n",
        "            nn.Linear(128, 64),\n",
        "            # 활성화 함수 ReLU 적용\n",
        "            nn.ReLU(),\n",
        "            # 은닉층(64) → 출력층(10 클래스)\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    # 순전파(forward) 과정 정의\n",
        "    def forward(self, x):\n",
        "        # 입력 데이터를 평탄화하여 벡터 형태로 변환\n",
        "        x = self.flatten(x)\n",
        "        # 정의한 모델 레이어들을 통과시켜 출력 반환\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "_uQPpAkI_rH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 다음 코드 셀은 모델 학습에서의 경고 발생 제거"
      ],
      "metadata": {
        "id": "I9-CzO9dSA5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU의 SM(Streaming Multiprocessor) 수가 적어 경고 발생 가능 제거\n",
        "import torch._inductor.config as inductor_cfg\n",
        "# SM(Streaming Multiprocessor) = GPU의 핵심 연산 단위\n",
        "inductor_cfg.max_autotune_gemm = False  # 해당 모드 사용 안 함"
      ],
      "metadata": {
        "id": "j5tEfmjC_wSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU(cuda)가 사용 가능하면 GPU에, 불가능하면 CPU에 연산을 수행하도록 장치를 설정함\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# DNN 모델 객체를 생성하고, 앞서 설정한 장치(device)로 모델을 이동시킴\n",
        "model = DNN().to(device)\n",
        "# PyTorch 2.0의 torch.compile 기능을 활용해 모델을 컴파일하여 실행 속도를 최적화함\n",
        "compiled_model = torch.compile(model)\n",
        "\n",
        "# 손실 함수와 옵티마이저\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(compiled_model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "pVvbU8FjRlbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 루프\n",
        "for epoch in range(epochs): # 전체 에폭 반복\n",
        "    compiled_model.train() # 학습 모드 설정\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in train_loader: # 배치 반복\n",
        "        data, target = data.to(device), target.to(device) # 입력/라벨 GPU로 이동\n",
        "\n",
        "        # 순전파 → 손실 → 역전파 → 옵티마이저 스텝\n",
        "        optimizer.zero_grad()\n",
        "        output = compiled_model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        # 모델 예측 결과(output)에서 예측한 가장 큰 값의\n",
        "        # 인덱스(argmax)를 뽑아 실제 정답(target)과 비교\n",
        "        # 맞춘 개수를 세어서 correct 변수에 누적함\n",
        "        correct += (output.argmax(1) == target).sum().item()\n",
        "\n",
        "    # 정확도 계산\n",
        "    accuracy = 100. * correct / len(train_loader.dataset)\n",
        "    # 에폭별 결과 출력\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:8.4f}, Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BclgkKqc_8bn",
        "outputId": "c98883b4-21b6-4073-daf6-c69a0bc174d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 322.5224, Accuracy: 90.30%\n",
            "Epoch 2, Loss: 134.3002, Accuracy: 95.67%\n",
            "Epoch 3, Loss:  91.6116, Accuracy: 97.11%\n",
            "Epoch 4, Loss:  68.2185, Accuracy: 97.75%\n",
            "Epoch 5, Loss:  53.2591, Accuracy: 98.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 루프\n",
        "compiled_model.eval()\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = compiled_model(data)\n",
        "        correct += (output.argmax(1) == target).sum().item()\n",
        "\n",
        "test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "XdKvKskFSQlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed7525b-8cf0-4438-e508-945855a3d0dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 97.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 종료"
      ],
      "metadata": {
        "id": "nkcbDpibBf4T"
      }
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soobook/PyTorch-DL/blob/main/code/PT02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2회차: PyTorch 설치 및 기초 코딩"
      ],
      "metadata": {
        "id": "SazHYg839Ty7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CUDA(Compute Unified Device Architecture)\n",
        "- NVIDIA에서 만든 병렬 연산용 프로그래밍 프레임워크\n",
        "- GPU를 범용 컴퓨팅(GPGPU: General Purpose GPU) 작업에 활용"
      ],
      "metadata": {
        "id": "dYwn4WGEyY8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(f'파이토치 버전: {torch.__version__}')\n",
        "print(\"GPU\" if torch.cuda.is_available() else \"CPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qRQVy0rWF1D",
        "outputId": "0e4a27ce-5945-46c2-9319-73f70f8e494f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파이토치 버전: 2.8.0+cu126\n",
            "GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch 및 라이브러리 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "vyCAIVG4SZFs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "N8nEcyfkVw_K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리 및 로딩\n",
        "# 이미지 픽셀 값을 [0, 255] 정수 값에서 [0.0, 1.0] 범위의 float 텐서로 변환\n",
        "transform = transforms.ToTensor()\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGJXredwV1Hf",
        "outputId": "44ee78af-8dc0-4e13-c6c6-df8f86201419"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 20.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 482kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.50MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.48MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 미니배치 단위로 묶고, 자동으로 반복 가능한 형태로 변환\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "O-H1zcJ7_Mu8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_loader 정보 출력\n",
        "print(\"=== Train Loader Info ===\")\n",
        "print(f\"총 배치 수 (len): {len(train_loader)}\")    # 전체 배치 개수\n",
        "print(f\"총 샘플 수: {len(train_loader.dataset)}\")  # 전체 데이터 수\n",
        "print(f\"총 배치 수 (직접계산): {len(train_loader.dataset)//batch_size + 1}\")\n",
        "\n",
        "# 첫 번째 배치 샘플 shape 확인\n",
        "for images, labels in train_loader:\n",
        "    print(f\"이미지 shape: {images.shape}\")         # 예: [batch_size, 1, 28, 28]\n",
        "    print(f\"레이블 shape: {labels.shape}\")         # 예: [batch_size]\n",
        "    print(f\"데이터 타입: {images.dtype}, 라벨 dtype: {labels.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU5xTuWgXlId",
        "outputId": "6ab9a930-5d86-4e8e-b724-1caf5b7349ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train Loader Info ===\n",
            "총 배치 수 (len): 938\n",
            "총 샘플 수: 60000\n",
            "총 배치 수 (직접계산): 938\n",
            "이미지 shape: torch.Size([64, 1, 28, 28])\n",
            "레이블 shape: torch.Size([64])\n",
            "데이터 타입: torch.float32, 라벨 dtype: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_loader 정보 출력\n",
        "print(\"\\n=== Test Loader Info ===\")\n",
        "print(f\"총 배치 수 (len): {len(test_loader)}\")\n",
        "print(f\"총 샘플 수: {len(test_loader.dataset)}\")\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    print(f\"이미지 shape: {images.shape}\")\n",
        "    print(f\"레이블 shape: {labels.shape}\")\n",
        "    print(f\"데이터 타입: {images.dtype}, 라벨 dtype: {labels.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtAGk2LzYKkM",
        "outputId": "8a480e40-8ef5-4f43-b5c9-c3f47c1ba30c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Test Loader Info ===\n",
            "총 배치 수 (len): 157\n",
            "총 샘플 수: 10000\n",
            "이미지 shape: torch.Size([64, 1, 28, 28])\n",
            "레이블 shape: torch.Size([64])\n",
            "데이터 타입: torch.float32, 라벨 dtype: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch의 기본 신경망 모듈 nn.Module을 상속받아 DNN 클래스 정의\n",
        "class DNN(nn.Module):\n",
        "\n",
        "    # 클래스 초기화 메서드: 모델의 레이어들을 정의\n",
        "    def __init__(self):\n",
        "        # 부모 클래스(nn.Module)의 생성자를 호출해 초기화\n",
        "        super(DNN, self).__init__()\n",
        "        # 입력 데이터를 1차원으로 평탄화(28x28 → 784차원)\n",
        "        self.flatten = nn.Flatten()\n",
        "        # 여러 층을 순차적으로 쌓은 신경망 정의\n",
        "        self.model = nn.Sequential(\n",
        "            # 입력층(784) → 은닉층(128)\n",
        "            nn.Linear(28*28, 128),\n",
        "            # 활성화 함수 ReLU 적용\n",
        "            nn.ReLU(),\n",
        "            # 은닉층(128) → 은닉층(64)\n",
        "            nn.Linear(128, 64),\n",
        "            # 활성화 함수 ReLU 적용\n",
        "            nn.ReLU(),\n",
        "            # 은닉층(64) → 출력층(10 클래스)\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    # 순전파(forward) 과정 정의\n",
        "    def forward(self, x):\n",
        "        # 입력 데이터를 평탄화하여 벡터 형태로 변환\n",
        "        x = self.flatten(x)\n",
        "        # 정의한 모델 레이어들을 통과시켜 출력 반환\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "_uQPpAkI_rH6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU(cuda)가 사용 가능하면 GPU에, 불가능하면 CPU에 연산을 수행하도록 장치를 설정함\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# DNN 모델 객체를 생성하고, 앞서 설정한 장치(device)로 모델을 이동시킴\n",
        "model = DNN().to(device)\n",
        "# PyTorch 2.0의 torch.compile 기능을 활용해 모델을 컴파일하여 실행 속도를 최적화함\n",
        "compiled_model = torch.compile(model)\n",
        "\n",
        "# 손실 함수와 옵티마이저\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(compiled_model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "pVvbU8FjRlbc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 루프\n",
        "for epoch in range(epochs): # 전체 에폭 반복\n",
        "    compiled_model.train() # 학습 모드 설정\n",
        "    total_loss = 0         # 에폭별 손실값\n",
        "    correct = 0            # 에폭별 정답수\n",
        "    for data, target in train_loader: # 배치 반복\n",
        "        data, target = data.to(device), target.to(device) # 입력/라벨 GPU로 이동\n",
        "\n",
        "        # 순전파 → 손실 → 역전파 → 옵티마이저 스텝\n",
        "        optimizer.zero_grad() # 옵티마이저의 기울기 0으로 초기화\n",
        "        output = compiled_model(data) # 모델로 출력 값 저장\n",
        "        loss = criterion(output, target) # 손실함수로 손실값 저장\n",
        "        loss.backward()   # 역전파로 기울기 수정\n",
        "        optimizer.step()  # 옵티마이저로 파러미터인 기중치와 편향 수정\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        # 모델의 예측값(output.argmax(1))과 실제 정답(target)을 비교하여 맞춘 개수를 누적\n",
        "        correct += (output.argmax(1) == target).sum().item()\n",
        "\n",
        "    # 정확도 계산\n",
        "    accuracy = 100. * correct / len(train_loader.dataset)\n",
        "    # 에폭별 결과 출력\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:8.4f}, Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BclgkKqc_8bn",
        "outputId": "fe3dfd86-9513-4b8a-add2-25a2087cee8c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W1013 08:36:09.954000 576 torch/_inductor/utils.py:1436] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 318.9353, Accuracy: 90.27%\n",
            "Epoch 2, Loss: 129.8727, Accuracy: 95.88%\n",
            "Epoch 3, Loss:  88.4028, Accuracy: 97.20%\n",
            "Epoch 4, Loss:  68.0790, Accuracy: 97.76%\n",
            "Epoch 5, Loss:  52.8591, Accuracy: 98.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 모드로 평가\n",
        "compiled_model.eval()\n",
        "correct = 0\n",
        "# 평가할 때는 기울기(gradient) 계산이 필요 없음\n",
        "# 메모리 사용을 줄이고 속도 향상됨\n",
        "# autograd를 끄는 것으로, 오직 순전파(forward)만 수행\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = compiled_model(data)\n",
        "        # 모델의 예측값(output.argmax(1))과 실제 정답(target)을 비교하여 맞춘 개수를 누적\n",
        "        correct += (output.argmax(1) == target).sum().item()\n",
        "\n",
        "test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "XdKvKskFSQlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "141b6fc7-8e51-4ec8-ab2f-6bbf52bc37a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 97.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 종료"
      ],
      "metadata": {
        "id": "nkcbDpibBf4T"
      }
    }
  ]
}